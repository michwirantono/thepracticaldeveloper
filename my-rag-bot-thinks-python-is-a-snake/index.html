<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>My RAG bot thinks Python is a snake</title>
  <style>
    body {
      font-family: sans-serif;
      line-height: 1.6;
      padding: 20px;
      max-width: 800px;
      margin: auto;
    }
    h1 {
      font-size: 2.5em;
      margin-bottom: 0.5em;
    }
    h2 {
      font-size: 1.5em;
      margin-top: 2em;
    }
    pre {
      background-color: #f4f4f4;
      padding: 10px;
      overflow-x: auto;
    }
    code {
      font-family: monospace;
    }
  </style>
</head>
<body>
  <article>
    <header>
      <h1>My RAG bot thinks Python is a snake</h1>
      <p><strong>Originally published on <a href="https://dev.to/0xt12s/my-rag-bot-thinks-python-is-a-snake-24on" target="_blank" rel="noopener noreferrer">dev.to</a> by 0xt12s on June 19, 2025</strong></p>
    </header>
    <section>
      <p>Remember yesterday when I fixed my hallucination problem? Woke up to this gem:</p>
      <blockquote>
        <p><em>“Python decorators work like a python snake constricting its prey.”</em></p>
      </blockquote>
      <p>My senior engineer just stared at me.</p>
      <p>Apparently fixing general hallucinations wasn’t enough. Now my bot was creatively misinterpreting every technical term it could find. Kafka became literary analysis. Circuit breakers became electrical safety lessons. Had to fix this before the whole engineering team revolted.</p>
    </section>
    <section>
      <h2>Quick answers for the desperate</h2>
      <dl>
        <dt><strong>Q: How can I detect when my LangChain RAG pipeline hallucinates technical terminology?</strong></dt>
        <dd>Pattern matching for danger words works. If your bot explains “Python” with “snake” or “Kafka” with “author”, you've got terminology hallucination. Takes ~80 ms to check.</dd>
        <dt><strong>Q: What's the most effective way to prevent domain terminology confusion in production RAG systems?</strong></dt>
        <dd>Inject correct definitions before the LLM sees anything. Pre-populate context with your glossary. Stopped 95% of our terminology disasters.</dd>
        <dt><strong>Q: Should I use pre-filtering or post-processing for terminology validation?</strong></dt>
        <dd>Both. Pre-filter removes obviously wrong contexts (Python + reptile docs). Post-process catches creative interpretations. Belt and suspenders.</dd>
        <dt><strong>Q: How do I handle ambiguous technical terms in my RAG pipeline?</strong></dt>
        <dd>Force disambiguation in your prompts. Explicitly state “Python (programming language, NOT the snake)”. Sounds dumb, works great.</dd>
      </dl>
    </section>
    <section>
      <h2>The morning logs of shame</h2>
      <pre><code>user: "explain our circuit breaker pattern"
bot: "circuit breakers are electrical safety devices that stop current flow..."
user: "what's kafka in our stack?"
bot: "kafka, named after franz kafka, handles messages with existential reliability..."
</code></pre>
      <p>We use Hystrix, not electrical circuits. And that Kafka explanation? Our CTO called it "poetic but useless."</p>
    </section>
    <section>
      <h2>Why yesterday's fix missed this</h2>
      <p>My pattern detection caught lies about features. But terminology? Different beast:</p>
      <ul>
        <li>LLMs know multiple meanings (Python = snake AND language)</li>
        <li>Retrieval gets partial matches</li>
        <li>Bot fills gaps with general knowledge</li>
      </ul>
    </section>
    <section>
      <h2>The 20-minute panic fix</h2>
      <pre><code>class TerminologyValidator:
    def __init__(self):
        self.danger_terms = {
            "python": ["snake", "reptile", "constrictor"],
            "java": ["coffee", "island", "indonesian"],
            "rust": ["corrosion", "oxidation", "metal"],
            "kafka": ["franz", "author", "metamorphosis"]
        }
    def check_response(self, query, response):
        disasters = []
        ...
        return disasters
</code></pre>
    </section>
    <section>
      <h2>Definition injection that actually works</h2>
      <pre><code>SAFE_DEFINITIONS = {
    "python": "high-level programming language",
    "circuit breaker": "resilience pattern preventing cascading failures",
    "kafka": "distributed event streaming platform"
}
def inject_glossary(query, retrieved_docs):
    ...
    glossary_doc = Document(...)
    retrieved_docs.insert(0, glossary_doc)
    return retrieved_docs
</code></pre>
    </section>
    <section>
      <h2>The prompt that saved my job</h2>
      <pre><code>TERMINOLOGY_PROMPT = """
You are a technical assistant.
CRITICAL: For these terms, ONLY use technical meanings:
- Python (programming language, NEVER the snake)
- Java (programming language, NEVER coffee)
- Kafka (streaming platform, NEVER the author)
Context: {context}
Question: {question}
Answer using technical definitions only:"""
</code></pre>
    </section>
    <section>
      <h2>Damage report</h2>
      <ul>
        <li>Morning: 47 terminology disasters</li>
        <li>After fix: 2 (both edge cases)</li>
        <li>Response time: +80 ms (worth it)</li>
        <li>Engineer trust: restored</li>
      </ul>
      <p>Tomorrow: handling when the bot explains "git" as British slang. Because apparently that’s also a thing.</p>
    </section>
    <footer>
      <p><em>— 0xt12s</em></p>
    </footer>
  </article>
</body>
</html>
